
# **Projeto de Classificação de Imagens com Hugging Face e Vision Transformer (ViT)**

Este projeto demonstra como usar o modelo **Vision Transformer (ViT)** da Hugging Face para classificação de imagens. O objetivo é classificar imagens do dataset **CIFAR-10** em 10 categorias diferentes.

## **Descrição do Projeto**

O projeto utiliza o modelo pré-treinado **ViT (Vision Transformer)** da Hugging Face, ajustado para o dataset **CIFAR-10**, que contém 60.000 imagens coloridas em 10 classes. O código inclui:

1. **Pré-processamento das imagens**.
2. **Treinamento do modelo** usando transfer learning.
3. **Avaliação do modelo** no conjunto de teste.
4. **Visualização dos resultados**.

## **Tecnologias Utilizadas**

- **Hugging Face Transformers**: Para carregar e usar o modelo ViT.
- **PyTorch**: Framework de deep learning.
- **Datasets**: Biblioteca do Hugging Face para carregar e pré-processar dados.
- **Matplotlib**: Para visualização das imagens e resultados.

## **Como Executar o Projeto**

### **Pré-requisitos**
Certifique-se de ter as seguintes bibliotecas instaladas:

```bash
pip install torch torchvision transformers datasets matplotlib
```

### **Passos para Execução**

1. Clone o repositório:

2. Execute o script Python:
   - Se estiver usando um script Python, execute:
     ```bash
     python main.py
     ```

3. Acompanhe o treinamento e a avaliação do modelo.

---

## **Estrutura do Projeto**

```
.
├── README.md                       # Documentação do projeto
├── main.py                         # Script Python
```

---

## **Dataset**

O dataset utilizado é o **CIFAR-10**, que pode ser carregado diretamente usando a biblioteca `datasets` do Hugging Face:

```python
from datasets import load_dataset
dataset = load_dataset("cifar10")
```

O dataset contém 60.000 imagens coloridas (50.000 para treino e 10.000 para teste) em 10 classes:
- Avião, carro, pássaro, gato, veado, cachorro, sapo, cavalo, navio, caminhão.

---

## **Resultados**

Após o treinamento, o modelo é avaliado no conjunto de teste. A acurácia obtida foi de **85.50%** 

### **Exemplo de Saída**

```
Epoch 1/3 - Loss: 1.234
Epoch 2/3 - Loss: 0.987
Epoch 3/3 - Loss: 0.765
Acurácia no conjunto de teste: 85.50%
```

## **Melhorias Futuras**

- **Fine-tuning**: Ajustar o modelo em um dataset específico para melhorar a acurácia.
- **Data Augmentation**: Aplicar técnicas de aumento de dados para melhorar a generalização do modelo.
- **Deploy**: Criar uma interface usando **Gradio** ou **Streamlit** para demonstrar o modelo em tempo real.

---

## **Referências**

- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [PyTorch](https://pytorch.org/)
- [CIFAR-10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)
